{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# numpy 소수점 4째자리까지 표현\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbcdc4d",
   "metadata": {},
   "source": [
    "### 데이터셋 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8581938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing()\n",
    "\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3b10e",
   "metadata": {},
   "source": [
    "**컬럼 소개 (California Housing Dataset)**\n",
    "\n",
    "행의 수 : 20640 <br>\n",
    "컬럼 수 : 8 \n",
    "\n",
    "* **MedInc**: 블록 그룹의 중간 소득\n",
    "* **HouseAge**: 블록 그룹의 중간 주택 연령\n",
    "* **AveRooms**: 가구당 평균 방 수\n",
    "* **AveBedrms**: 가구당 평균 침실 수\n",
    "* **Population**: 블록 그룹 인구\n",
    "* **AveOccup**: 가구당 평균 거주자 수\n",
    "* **Latitude**: 블록 그룹 위도\n",
    "* **Longitude**: 블록 그룹 경도\n",
    "* **MedHouseVal**: 중간 주택 가격 (타겟, $100,000 단위)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e0ce0",
   "metadata": {},
   "source": [
    "### 데이터프레임으로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74389004",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814172de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MedHouseVal'] = data['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89cda3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170cc9e",
   "metadata": {},
   "source": [
    "### 지도위에 데이터를 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812dd079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import branca.colormap as cm\n",
    "\n",
    "# 위도, 경도의 평균을 중심으로 지도 생성\n",
    "center = [df['Latitude'].mean(), df['Longitude'].mean()]\n",
    "m = folium.Map(location=center, zoom_start=6)\n",
    "\n",
    "# 데이터가 많으므로 일부만 샘플링하여 시각화 (예: 1000개)\n",
    "sample_df = df.sample(n=1000, random_state=42)\n",
    "\n",
    "# 가격에 따른 색상 매핑 함수 (Linear Colormap)\n",
    "colormap = cm.LinearColormap(colors=['blue', 'green', 'yellow', 'red'], \n",
    "                             index=[sample_df['MedHouseVal'].min(), sample_df['MedHouseVal'].max()],\n",
    "                             vmin=sample_df['MedHouseVal'].min(),\n",
    "                             vmax=sample_df['MedHouseVal'].max())\n",
    "colormap.caption = 'Median House Value'\n",
    "colormap.add_to(m)\n",
    "\n",
    "for idx, row in sample_df.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['Latitude'], row['Longitude']],\n",
    "        radius=5,  # 반지름은 고정 (가격과 무관)\n",
    "        color=colormap(row['MedHouseVal']),\n",
    "        fill=True,\n",
    "        fill_color=colormap(row['MedHouseVal']),\n",
    "        fill_opacity=0.7,\n",
    "        tooltip=f\"Price: {row['MedHouseVal']}\"\n",
    "    ).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d1d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706a70f",
   "metadata": {},
   "source": [
    "### 데이터를 분할(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b813845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('MedHouseVal', axis=1), df['MedHouseVal'], test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e565a555",
   "metadata": {},
   "source": [
    "### 평가지표(MSE,MAE,RMSE,R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aed568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58fffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "my_predictions = {}\n",
    "\n",
    "colors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown',\n",
    "          'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick',\n",
    "          'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive', \n",
    "          'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate',\n",
    "          'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray', \n",
    "          'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato'\n",
    "         ]\n",
    "\n",
    "# plot_predictions : 예측값과 실제값을 산점도로 비교하여 시각화\n",
    "def plot_predictions(name_, pred, actual):\n",
    "    df = pd.DataFrame({'prediction': pred, 'actual': actual})\n",
    "    df = df.sort_values(by='actual').reset_index(drop=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.scatter(df.index, df['prediction'], marker='x', color='r')\n",
    "    plt.scatter(df.index, df['actual'], alpha=0.7, marker='o', color='black')\n",
    "    plt.title(name_, fontsize=15)\n",
    "    plt.legend(['prediction', 'actual'], fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "# mse 기준으로 모델의 성능 평가를 해주는 함수\n",
    "def mse_eval(name_, pred, actual):\n",
    "    global predictions\n",
    "    global colors\n",
    "\n",
    "    # 산점도를 그려주고(예측값, 정답값)\n",
    "    plot_predictions(name_, pred, actual)\n",
    "\n",
    "    # mse 계산 출력\n",
    "    mse = mean_squared_error(pred, actual)\n",
    "    my_predictions[name_] = mse\n",
    "\n",
    "    # 모델별 성능을 비교하기 위해 sorted\n",
    "    y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    df = pd.DataFrame(y_value, columns=['model', 'mse'])\n",
    "    print(df)\n",
    "    min_ = df['mse'].min() - 10\n",
    "    max_ = df['mse'].max() + 10\n",
    "    \n",
    "    length = len(df)\n",
    "    \n",
    "    # 모델들을 비교해서 barh로 그려준다.\n",
    "    plt.figure(figsize=(10, length))\n",
    "    ax = plt.subplot()\n",
    "    ax.set_yticks(np.arange(len(df)))\n",
    "    ax.set_yticklabels(df['model'], fontsize=15)\n",
    "    bars = ax.barh(np.arange(len(df)), df['mse'])\n",
    "    \n",
    "    for i, v in enumerate(df['mse']):\n",
    "        idx = np.random.choice(len(colors))\n",
    "        bars[i].set_color(colors[idx])\n",
    "        ax.text(v + 2, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold')\n",
    "        \n",
    "    plt.title('MSE Error', fontsize=18)\n",
    "    plt.xlim(min_, max_)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# 리스트에 있는 모델중에 하나를 삭제하는 함수\n",
    "def remove_model(name_):\n",
    "    global my_predictions\n",
    "    try:\n",
    "        del my_predictions[name_]\n",
    "    except KeyError:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9778f9e7",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c9db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모델 생성\n",
    "linear_reg = LinearRegression(n_jobs=-1)\n",
    "\n",
    "# 2. 모델 학습\n",
    "linear_reg.fit(X_train, y_train)\n",
    "\n",
    "# 3. 모델 예측\n",
    "y_pred = linear_reg.predict(X_test)\n",
    "\n",
    "# 4. 모델 평가\n",
    "mse_eval('Linear Regression',y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467008c7",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ce62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모델 생성\n",
    "ridge = Ridge(alpha=0.001)\n",
    "\n",
    "# 2. 모델 학습\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# 3. 모델 예측\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "# 4. 모델 평가\n",
    "mse_eval('ridge',y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모델 생성\n",
    "lasso = Lasso(alpha=0.01)\n",
    "\n",
    "# 2. 모델 학습\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# 3. 모델 예측\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "# 4. 모델 평가\n",
    "mse_eval('lasso(alpha=0.01)',y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4722d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모델 생성\n",
    "elasticnet = ElasticNet(alpha=0.5, l1_ratio=0.1)\n",
    "\n",
    "# 2. 모델 학습\n",
    "elasticnet.fit(X_train, y_train)\n",
    "\n",
    "# 3. 모델 예측\n",
    "y_pred = elasticnet.predict(X_test)\n",
    "\n",
    "# 4. 모델 평가\n",
    "mse_eval('elasticnet(alpha=0.5,l1_raio=0.1)',y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a7fa0e",
   "metadata": {},
   "source": [
    "### PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2048ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. (파이프 라인)모델 생성\n",
    "elasticnet_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    ElasticNet(alpha=0.1, l1_ratio=0.1)\n",
    ")\n",
    "\n",
    "# 2. 모델 학습\n",
    "elasticnet_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 3. 모델 예측\n",
    "y_pred = elasticnet_pipeline.predict(X_test)\n",
    "\n",
    "# 4. 모델 평가\n",
    "mse_eval('STD elastic(alpha=0.1,l1_raio=0.1)',y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67e8332",
   "metadata": {},
   "source": [
    "## **앙상블(Ensemble) 모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edeae16",
   "metadata": {},
   "source": [
    "### Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# 앞에서 학습이 완료된 모델을 가져오기\n",
    "single_models = [ \n",
    "    ('lasso', lasso),\n",
    "    ('ridge', ridge),\n",
    "    ('linear_reg',linear_reg),\n",
    "    ('std_elastic', elasticnet_pipeline)    \n",
    "]\n",
    "\n",
    "# 1. 모델 생성\n",
    "voting_reg = VotingRegressor(single_models, n_jobs=-1)\n",
    "\n",
    "# 2. 모델 학습\n",
    "voting_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 예측\n",
    "y_pred = voting_reg.predict(X_test)\n",
    "\n",
    "# 4. 모델 평가\n",
    "mse_eval('voting_regressor',y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b176ca",
   "metadata": {},
   "source": [
    "### Bagging방식의 ensemble\n",
    "Bootstrap AGGregatING : BAGGING\n",
    "\n",
    "#### Randomg Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e43cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 1. 모델 생성\n",
    "rf_reg = RandomForestRegressor()\n",
    "\n",
    "# 2. 모델 학습\n",
    "rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 예측\n",
    "y_pred = rf_reg.predict(X_test)\n",
    "\n",
    "# 4. 모델 평가\n",
    "mse_eval('random forest regressor',y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff6a32e",
   "metadata": {},
   "source": [
    "### GridSearchCV로 rf_reg를 하이퍼파라메터 튜닝\n",
    "**나중에 다음과 같은 라이브러리도 사용해 보기를 권장**<br>\n",
    "AutoML 혹은 자동 하이퍼파라메터 튜닝 : Optuna, H2O, Autogluon(AWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e87d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. RF 모델 생성\n",
    "rf_reg_cv = RandomForestRegressor(random_state=42)\n",
    "param_grid = { # 5*7=35가지 조합 학습하고 비교\n",
    "    'n_estimators': [500,600,700,800,900],\n",
    "    'max_depth': [None]\n",
    "    }\n",
    "# GridSearchCV 모델 생성 \n",
    "grid_rg_reg = GridSearchCV(rf_reg_cv, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# 2. 모델 학습\n",
    "grid_rg_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(grid_rg_reg.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score','split3_test_score', 'split4_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b97dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GridSearch 최적 파라미터: ', grid_rg_reg.best_params_)\n",
    "print('GridSearch 최고 점수: ', grid_rg_reg.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c4b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_rg_reg.best_params_로 모델 가져오기\n",
    "best_rg_model = grid_rg_reg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 예측\n",
    "y_pred = best_rg_model.predict(X_test)\n",
    "\n",
    "# 4. 모델 평가\n",
    "mse_eval('RF GridSearchCV', y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf2103",
   "metadata": {},
   "source": [
    "### 부스팅(Boosting)\n",
    "* 부스팅은 여러 개의 약한 학습기를 순차적으로 학습시켜서 최종적으로 강한 학습기를 만드는 방법.\n",
    "* 장점 : 성능이 뛰어나고, 별도의 특성 선택이 필요하지 않음.\n",
    "* 단점 : 잘못된 레이블링이나, 이상치(Outlier)에 민감할 수 있다. -> 과적합(Overfitting)이 발생\n",
    "\n",
    "GBM, AdaBoost, XGBoost, LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab16784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('https://keras.io/img/graph-kaggle-1.jpeg', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b873e28",
   "metadata": {},
   "source": [
    "#### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b112157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# 1. 모델 생성\n",
    "gbr = GradientBoostingRegressor(max_depth=2, n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# 2. 모델 학습\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd1308",
   "metadata": {},
   "source": [
    "### 연습용 데이터셋을 만들어서 GBM 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c2f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 예측\n",
    "y_pred = gbr.predict(X_test)\n",
    "\n",
    "# 4. 모델 평가\n",
    "mse_eval('gbr', y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d60e8",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost는 sklearn안에 기본 알고리즘이 아니다.\n",
    "# %pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0057cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 1. 모델 생성\n",
    "xgb_reg = XGBRegressor(random_state=42, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8)\n",
    "\n",
    "# 2. 모델 학습\n",
    "xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618bb5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 예측\n",
    "y_pred = xgb_reg.predict(X_test)\n",
    "\n",
    "# 4. 모델 평가\n",
    "mse_eval('xgb_reg', y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efda34",
   "metadata": {},
   "source": [
    "### LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69fb72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37123e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# 1. 모델 생성\n",
    "lgbm_reg = LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    # 아래 파라미터들을 하나씩 조정해 보세요\n",
    "    num_leaves=31,            # 늘리면 더 복잡한 모델 (너무 크면 과적합 주의)\n",
    "    min_child_samples=10,     # 줄이면 더 미세한 분기 가능 (기본값 20)\n",
    "    min_child_weight=0.001,   # 줄이면 더 작은 단위로 분기\n",
    "    verbose=-1                # 경고 메시지를 숨기고 싶을 때 사용\n",
    ")\n",
    "\n",
    "# 2. 모델 학습\n",
    "lgbm_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 예측\n",
    "y_pred = lgbm_reg.predict(X_test)\n",
    "\n",
    "# 4. 모델 평가\n",
    "mse_eval('lgbm_reg', y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54046e81",
   "metadata": {},
   "source": [
    "###  Stacking\n",
    "* 개별 모델(전단 예측기)이 예측한 데이터를 기반으로 최종 예측기가 종합하여 예측한다.\n",
    "* 데이터셋이 적은 경우 과대 적합(Overfitting)이 발생할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking Model -> 서로 다른 모델들을 개별모델(전단 예측기)로 사용할 수 있다.\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "stack_models =[\n",
    "    ('lgbm', lgbm_reg),\n",
    "    ('xgb', xgb_reg),\n",
    "    ('rf', rf_reg),\n",
    "    ('gbr', gbr)\n",
    "]\n",
    "\n",
    "# 1. 모델 생성\n",
    "stack_reg = StackingRegressor(estimators=stack_models, final_estimator=lgbm_reg)\n",
    "\n",
    "# 2. 모델 학습\n",
    "stack_reg.fit(X_train, y_train)\n",
    "\n",
    "# 3. 모델 예측\n",
    "y_pred = stack_reg.predict(X_test)\n",
    "\n",
    "# 4 모델 평가\n",
    "mse_eval('stacking Ensemble', y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
